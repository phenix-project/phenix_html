
<!-- REMARK PHENIX TITLE START Put your title here -->


<H4><U>Automated Model Building and Rebuilding using AutoBuild
</U></H4>


<!-- REMARK PHENIX TITLE END -->

<!-- REMARK PHENIX BODY START   Put your text here. 
Anything enclosed in header html H4 H5 etc will go in the table of contents -->


      <P><H5><U>Author(s)</U></H5><P>
<UL><LI>AutoBuild Wizard: Tom Terwilliger
<LI>PHENIX GUI and PDS Server: Nigel W. Moriarty
<LI>phenix.refine: Ralf W. Grosse-Kunstleve, Peter Zwart and Paul D. Adams
<LI>RESOLVE: Tom Terwilliger
<LI>phenix.xtriage: Peter Zwart
</LI>
</UL>


      <P><H5><U>Purpose</U></H5><P>

<P><H5>Purpose of the AutoBuild Wizard</H5><P>

<P>The purpose of the AutoBuild Wizard is to provide a highly automated system
for model rebuilding and completion. The Wizard design allows the user to
specify data files and parameters through an interactive GUI, or alternatively
through a parameters file. The AutoBuild Wizard begins with datafiles with
structure factor amplitudes and uncertainties, along with either experimental
phase information or a starting model, carries out cycles of model-building
and refinement alternating with model-based density modification, and
producing a relatively complete atomic model. 

<P>The AutoBuild Wizard uses RESOLVE, xtriage and 
phenix.refine to build an atomic model, refine it, and improve
it with iterative density modification, refinement, and model-building
<P>The Wizard begins with either experimental phases (i.e., from AutoSol)
or with an atomic model that can be used to generate calculated phases.
The AutoBuild Wizard produces a refined model that can be nearly complete
if the data are strong and the resolution is about 2.5 A or better. At
lower resolutions (2.5 - 3 A) the model may be less complete and at 
resolutions > 3A the model may be quite incomplete and not well
refined.
<P> The AutoBuild Wizard can be used to generate OMIT maps (simple omit,
SA-omit, iterative-build omit) that can cover the entire unit cell or
specific residues in a PDB file.
<P> The AutoBuild Wizard can generate a set of models compatible with
experimental data (multiple_models)

      <P><H5><U>Usage</U></H5><P>
<P>The AutoBuild Wizard can be run from the PHENIX GUI, from the command-line, 
and from parameters files.  All three versions are identical except
in the way that they take commands from the user. 
See 
<a href="running-wizards.htm">
Using the PHENIX Wizards</a> 
for details of how to run a Wizard.
The command-line version will be described here.
<P>
<P><H5>How the AutoBuild Wizard works</H5><P>
<P>

<P>The AutoBuild Wizard begins with experimental structure factor amplitudes,
along with either experimental or model-based estimates of crystallographic
phases. The phase information is improved by using statistical density
modification to improve the correlation of NCS-related density in the map (if
present) and to improve the match of the distribution of electron densities in
the map with those expected from a model map. This improved map is then used
to build and refine an atomic model. 

<P>In subsequent cycles, the models from previous cycles are used as a source of
phase information in statistical density modification, iteratively improving
the quality of the map used for model-building. 

<P>Additionally, during the first few cycles additional phase information is
obtained by detecting and enhancing (1) the presence of commonly-found local
patterns of density in the map, and (2) the presence of density in the shape
of helices and strands. The final model obtained is analyzed for residue-based
map correlation and density at the coordinates of individual atoms, and an
analysis including a summary of atoms and residues that are in strong,
moderate, or weak density and out of density is provided.

<P><H5>Automation and user control</H5><P>

<P>The AutoBuild Wizard has been designed for ease of use combined with maximal
user control, with as many parameters set automatically by the Wizard as
possible, but maintaining parameters accessible to the user through a GUI and
through parameters files. The Wizard uses the input/output routines of
the cctbx library, allowing data files of many different formats so that the
user does not have to convert their data to any particular format before using
the Wizard. Use of the phenix.refine refinement package in the AutoBuild
Wizard allows a high degree of automation of refinement so that the neither
user nor Wizard is required to specify parameters for refinement. The
phenix.refine package automatically includes a bulk solvent model and
automatically places solvent molecules.

<P><H5>Core modules in the AutoBuild Wizard</H5><P>

<P>The five core modules in the AutoBuild Wizard are 
<UL><LI>(1) building a new model into an electron density map 

<LI>(2) rebuilding an existing model 

<LI>(3) refinement 

<LI>(4) iterative model- building beginning from experimental phase
information, and 

<LI>(5) iterative model-building beginning from a model. 
</LI>
</UL>

<P>The standard procedures available in the AutoBuild Wizard that are based on
these modules include: 


<UL><LI>(a) model-building and completion starting from experimental phases, 

<LI>(b) rebuilding a model from scratch, with or without experimental phase
information, and 

<LI>(c) rebuilding a model in place, maintaining connectivity and sequence
register. 
</LI>
</UL>

<P>Starting from a set of experimental phases and structure factor amplitudes,
normally procedure (a) is carried out, and then the resulting model is rebuilt
with procedure (b). 

<P>Starting from a model (e.g., from molecular replacement) and experimental
structure factor amplitudes, procedure (c) is by default carried out if the
starting model differs less than about 50% in sequence from the desired model,
and otherwise procedure (b) is used. It is generally a good idea to specify
which you want to happen using the keyword 
&quot;rebuild_in_place=True&quot; (to keep the basic input model) or
&quot;rebuild_in_place=False&quot; (to build a new model).

<P><H5>What the AutoBuild wizard needs to run</H5><P>

<UL><LI>(1) a data file, optionally with phases and HL coeffs and freeR flag
    (w1.sca or data=w1.sca)
<LI>(2) a sequence file (seq.dat or seq_file=seq.dat) or a model
(coords.pdb or model=coords.pdb)
</LI>
</UL>


<P><H5>...and optional files</H5><P>

<UL><LI>(3) coefficients for a starting map (map_file=resolve.mtz)
<LI>(4) a file for refinement (refinement_file=exptl_fobs_freeR_flags.mtz)
<LI>(5) a high-resolution datafile (hires_file=high_res.sca)
</LI>
</UL>



<P><H5>Specifying which columns of data to use from input data files</H5><P>
<P>If one or more of your data files has column names that the Wizard
cannot identify automatically, you can specify them yourself. You
will need to provide one column "name" for each expected column of data,
with "None" for anything that is missing.

<P>For example, if your data file ref.mtz has columns FP SIGFP and FreeR
then you might specify
<PRE style="face=courier">refinement_file=ref.mtz
input_refinement_labels="FP SIGFP None None None None None None FreeR"
</PRE>

<P>The keywords for labels and anticipated input labels (program labels) are:

<PRE style="face=courier">input_labels (for data file): FP SIGFP PHIB FOM HLA HLB HLC HLD FreeR_flag
input_refinement_labels: FP SIGFP FreeR_flag
input_map_labels: FP PHIB FOM
input_hires_labels: FP SIGFP FreeR_flag
</PRE>

<P>You can find out all the possible label strings in a data file that
you might use by typing:
<PRE style="face=courier">phenix.autosol display_labels=w1.mtz  # display all labels for w1.mtz
</PRE>

<P>NOTES: if your data files contain a mixture of amplitude and intensity data
then only the amplitude data is available. If you have only intensity data in 
a data file and want to select specific columns, then you need to specify the
column names as they are after importing the data and conversion to 
amplitudes (see below under General Limitations for details).

<P><H5>Specifying other general parameters</H5><P>
<P>You can specify many more parameters as well. See the list of
keywords, defaults and descriptions at the end of this page and
also general information about running Wizards at
<a href="running-wizards.htm">
Using the PHENIX Wizards</a> 
for how to do this.  Some of the most common parameters are:
<PRE style="face=courier">data=w1.sca       # data file
model=coords.pdb  # starting model
rebuild_in_place=true # rebuild input model in place
rebuild_in_place=false # build a new model; add or subtract residues 
                       #   from input model as necessary
seq_file=seq.dat  # sequence file
map_file=map_coeffs.mtz # coefficients for a starting map for building
resolution=3     # dmin of 3 A
s_annealing=True  # use simulated annealing refinement at start of each cycle
n_cycle_build_max=5  # max number of build cycles (starting from experimental phases)
n_cycle_rebuild_max=5  # max number of rebuild cycles (starting from a model)
</PRE>

<P><H5>Running from a parameters file</H5><P>
You can run phenix.autobuild from a parameters file. This is often convenient
because you can generate a default one with:
<PRE style="face=courier">phenix.autobuild --show_defaults > my_autobuild.eff
</PRE>
and then you can just edit this file to match your needs and run it with:
<PRE style="face=courier">phenix.autobuild  my_autobuild.eff
</PRE>

<P><H5>Picking waters in AutoBuild</H5><P>
<P>By default AutoBuild will instruct phenix.refine to pick waters using its
standard procedure. This means that if the resolution of the data is
high enough (typically 3 A) then waters are placed.
<P>You can tell AutoBuild not to have phenix.refine pick waters with 
the command:
<PRE style="face=courier">place_waters=False
</PRE>
If you want to place waters at a lower resolution, you will need to
reset the low-resolution cutoff for placing waters in phenix.refine. You would
do that in a &quot;refinement_params.eff&quot; file containing lines like 
these (see below for 
passing parameters to phenix.refine with an &quot;.eff&quot; file):
<PRE style="face=courier">refinement {
  ordered_solvent {
    low_resolution = 2.8
  }
} 
</PRE>

<P><H5>Keeping waters from your input file in AutoBuild</H5><P>
<P>You can tell AutoBuild to keep the waters in your input file when you
are using rebuild_in_place (the default is to toss them and replace 
them with new ones).
You can say,
<PRE style="face=courier">keep_input_waters=True
place_waters=No
</PRE>
NOTE: If you specify keep_input_waters=True you 
should also specify either "place_waters=No" 
or "keep_pdb_atoms=No" .  This is because if place_waters=Yes and 
keep_pdb_atoms=Yes then phenix.refine will add waters and 
then the wizard will keep the new waters from the new PDB file 
created by phenix.refine preferentially over the ones in your input file.


<P><H5>Twinning and AutoBuild </H5><P>
<P>AutoBuild does not know about twinning, but you can incorporate
a twin law into the refinement steps in the AutoBuild procedure if your 
crystal is twinned. Use phenix.xtriage to identify twinning and the
twin law. Then specify the twin law in a parameters file (see next
section) and provide that to AutoBuild with the 
keyword such as &quot;refine_eff_file=twin_law.eff&quot;
<P>You may also want to try using the keyword
&quot;two_fofc_in_rebuild&quot; which will use the 2Fo-Fc map from
phenix.refine in model-building.

<P><H5>Specifying phenix.refine parameters</H5><P>
<P>You can control phenix.refine parameters that are not specified
directly by AutoBuild using a refinement parameters (.eff) file:
<PRE style="face=courier">refine_eff_file=refinement_params.eff    # set any phenix.refine params not set by AutoBuild
</PRE>
This file might contain a twin-law for refinement:
<PRE style="face=courier">refinement {
  twinning {
    twin_law = "-k, -h, -l"
  }
}
</PRE>
<P>
You can put any phenix.refine parameters in this file, but a few parameters
that are set directly by AutoBuild override your 
inputs from the refine_eff_file. These parameters are listed below.

<P>Refinement parameters that must be set using AutoBuild Wizard 
keywords (overwriting any values provided by user in input_eff_file)

<table border="1" width="92%" cellpadding="5px">
<tbody>

<tr>
 <td><B>phenix.refine keyword</B> </td>
 <td><B>Wizard keyword(s) and notes</B> </td>
</tr>

<tr>
 <td> refinement.main.number_of_macro_cycles </td>
 <td> ncycle_refine </td>
</tr>

<tr>
 <td> refinement.main.simulated_annealing </td>
 <td>s_annealing (only applies to 1st refinement in rebuild.
   SA in any other refinements controlled by input_eff_file, if any) </td>
</tr>

<tr>
 <td> refinement.ncs.find_automatically </td>
 <td> refine_with_ncs=True turns on automatic ncs search </td>
</tr>

<tr>
 <td> refinement.main.ncs </td>
 <td> refine_with_ncs=True turns on ncs </td>
</tr>

<tr>
 <td> refinement.ncs.coordinate_sigma </td>
 <td> Normally not set by Wizard. However if the Wizard keyword 
ncs_refine_coord_sigma_from_rmsd is True then the ncs coordinate sigma 
is equal to ncs_refine_coord_sigma_from_rmsd_ratio times the rmsd among ncs 
copies </td>
</tr>

<tr>
 <td> refinement.main.random_seed </td>
 <td> i_ran_seed sets the random seed at the beginning of a Wizard...
this affects refinement.main.random_seed but does not set it to
the value of i_ran_seed (because i_ran_seed gets updated by several
different routines)</td>
</tr>

<tr>
 <td> refinement.main.ordered_solvent </td>
 <td> place_waters=True will set ordered_solvent to True. Note that
  this only has an effect if the value of the resolution cutoff for
 adding waters (refinement.ordered_solvent.low_resolution)
 is higher than the resolution used for refinement.  </td>
</tr>

<tr>
 <td> refinement.main.ordered_solvent </td>
 <td> place_waters_in_combine=True will set ordered_solvent to True, only
 applying this to the final combination step of multiple-model
 generation. Note that
  this only has an effect if the value of the resolution cutoff for
 adding waters (refinement.ordered_solvent.low_resolution)
 is higher than the resolution used for refinement.  </td>
</tr>

<tr>
 <td> refinement.ordered_solvent.low_resolution </td>
 <td> ordered_solvent_low_resolution=3.0 (default) will set the
  resolution cutoff for adding waters 
(refinement.ordered_solvent.low_resolution) to 3 A. If the resolution
used for refinement is larger than the value of ordered_solvent_low_resolution
then ordered solvent is not added. </td>
</tr>

<tr>
 <td>refinement.main.use_experimental_phases </td>
 <td>use_mlhl=True will set refinement.main.use_experimental_phases to True</td>
</tr>

<tr>
 <td> refinement.refine.strategy   </td>
 <td> The Wizard keywords refine refine_b refine_xyz all affect 
refinement.refine.strategy. If refine=True then refinement is carried out. If
refine_b=True (default) isotropic displacement factors are refined.
If refine_xyz=True (default) coordinates are refined.</td>
</tr>

<tr>
 <td> refinement.main.occupancy_max       </td>
 <td> max_occ=1.0 sets the value of refinement.main.occupancy_max to 1.0. 
Default is to do nothing and use the default from phenix.refine (1.0) </td>
</tr>

<tr>
 <td> refinement.refine.occupancies.individual </td>
 <td> The combination of Wizard keywords of semet=True and
refine_se_occ=True will add "(name SE)" to the value of
refinement.refine.occupancies.individual. You can add to your
.eff file other names of atoms to have occupancies refined as well.
 </td>
</tr>

<tr>
 <td> refinement.main.high_resolution    </td>
 <td> Either of the Wizard keywords refinement_resolution and resolution 
will set the value of refinement.main.high_resolution, with 
refinement_resolution being used if available.  </td>
</tr>
<tr>
 <td> refinement.pdb_interpretation.link_distance_cutoff    </td>
 <td> link_distance_cutoff </td>
</tr>

</tbody>
</table>

<P>The following parameters controlling phenix.refine output
are set directly in AutoBuild and cannot be set by the user

<UL><LI> refinement.output.write_eff_file
<LI> refinement.output.write_geo_file
<LI> refinement.output.write_def_file
<LI> refinement.output.write_maps
<LI> refinement.output.write_map_coefficients
</LI>
</UL>


<P><H5>Specifying resolve/resolve_pattern parameters</H5><P>
<P>Similarly, you can control resolve and resolve_pattern parameters. For these
parameters, your inputs will not be overridden by AutoBuild. 
The format is a little tricky: you have to put two sets of 
quotes around the command like this:
<PRE style="face=courier">resolve_command="'resolution 200 3'"    # NOTE ' and " quotes
</PRE>
This will put the text
<PRE style="face=courier">resolution 200 3
</PRE>
at the end of every temporary command file created to run resolve.
(This is why it is not overridden by AutoBuild commands; they will all come 
before your commands in the resolve command file.) Note that 
some commands in resolve may be incompatible with this usage.

<P><H5>Including ligand coordinates in AutoBuild</H5><P>

<P> If your input PDB file contains ligands (anything other than solvent
that is not protein if your chain_type=PROTEIN, for example) then 
by default these
ligands will be kept, used in refinement, and written out to your output
PDB file.  Any solvent molecules will by default be discarded.
You can change this behavior by changing the keywords from these defaults:
<PRE style="face=courier">keep_input_ligands=True
keep_input_waters=False
</PRE>
The AutoBuild Wizard will use phenix.elbow to generate geometries for any
ligands that are not recognized.

<P>You can also tell AutoBuild to add the contents of any PDB files that
you wish to supply to the
current version of the structure just before refinement, so all the refined
models produced contain whatever AutoBuild has built, plus the contents of
these PDB files. This can be done through the GUI, the command-line, or
a parameters file. In the command-line version you do this with:
<PRE style="face=courier">input_lig_file_list=my_ligand.pdb
</PRE>
<P>NOTE: The files in 
input_lig_file_list will be edited to make them all HETATM records
to tell AutoBuild to ignore these residues in rebuilding.
<P>NOTE You may need to tell phenix.refine
about the geometry of your ligands. You will get an error message if
the ligand is not recognized and an automatic run of
phenix.elbow does not succeed in generating your ligand. 
In that case you will want to run
phenix.elbow to create a cif definition file for this ligand:
<PRE style="face=courier">phenix.elbow my_ligand.pdb --id=LIG
</PRE>
where LIG is the 3-letter ID code that you use in my_ligand.pdb
to identify your ligand. If the automatic run does not work you may need
to give phenix.elbow additional information to generate your ligand.
<P>Once phenix.elbow has generated your ligand
you can use the keyword "cif_def_file_list" to 
tell AutoBuild about this ligand:
<PRE style="face=courier">cif_def_file_list=elbow.LIG.my_ligand.pdb.cif
</PRE>

<P><H5>Specifying arbitrary commands and cif files for phenix.refine </H5><P>
<P>You can tell AutoBuild to apply any set of cif definitions to the model
during refinement by using a combination of specification files and the
commands cif_def_file_list and refine_eff_file_list:
<PRE style="face=courier">refine_eff_file_list=link.eff cif_def_file_list=link.cif
</PRE>
This example comes from the phenix.refine manual page in which a link is 
specified in a cif definition file link.cif:
<PRE style="face=courier"> data_mod_5pho
#
loop_
_chem_mod_atom.mod_id
_chem_mod_atom.function
_chem_mod_atom.atom_id
_chem_mod_atom.new_atom_id
_chem_mod_atom.new_type_symbol
_chem_mod_atom.new_type_energy
_chem_mod_atom.new_partial_charge
 5pho     add      .      O5T    O    OH      .
loop_
_chem_mod_bond.mod_id
_chem_mod_bond.function
_chem_mod_bond.atom_id_1
_chem_mod_bond.atom_id_2
_chem_mod_bond.new_type
_chem_mod_bond.new_value_dist
_chem_mod_bond.new_value_dist_esd
 5pho     add      O5T     P         coval        1.520    0.020
</PRE>
<P>and this is applied with a parameters file link.eff:
<PRE style="face=courier"> refinement.pdb_interpretation.apply_cif_modification
{
  data_mod = 5pho
  residue_selection = resname GUA and name O5T
}
</PRE>
<P>You can have any number of cif files and parameters files.


<P><H5><I>Output files from AutoBuild</I></H5><P>
<P>When you run AutoBuild the output files will be in a subdirectory with
your run number:
<PRE style="face=courier">AutoBuild_run_1_/   # subdirectory with results
</PRE>


<UL><LI>A summary file listing the results of the run and
the other files produced:
<PRE style="face=courier">AutoBuild_summary.dat  # overall summary
</PRE>

<LI>A warnings file listing any warnings about the run
<PRE style="face=courier">AutoBuild_warnings.dat  # any warnings
</PRE>

<LI>A file that lists all parameters and knowledge accumulated
by the Wizard during the run (some parts are binary and are not printed)
<PRE style="face=courier">AutoBuild_Facts.dat   # all Facts about the run
</PRE>

<LI>Final refined model
<PRE style="face=courier">overall_best.pdb
</PRE>
<p>NOTE: The &quot;overall_best.pdb&quot; file is always the current best
 model. Similarly &quot;overall_best_denmod_map_coeffs.mtz&quot; is always
the best map_coefficients file. The AutoBuild_summary.dat file lists
the names of the current best set of files. The contents of 
 &quot;overall_best.pdb&quot; and of the best model 
listed in AutoBuild_summary.dat will be the same.

<LI>Final map coefficients used to build refined model. Use FP PHIM FOMM in
maps. Normally this is a density-modified map from resolve. See also the
map coefficients from phenix.refine below. If you are using
Coot to display them, select "Open MTZ" (rather than AutoOpen MTZ).
<PRE style="face=courier">overall_best_denmod_map_coeffs.mtz
</PRE>

<LI>Final sigmaA-weighted 2mFo-DFc and Fo-Fc map coefficients from 
phenix.refine based on overall_best.pdb final model. The map coefficients
are 2FOFCWT PH2FOFCWT for the 2mFo-DFc map and FOFC and PHFOFC for the Fo-Fc
difference map.  See also the map coefficients from density modification above.
<PRE style="face=courier">overall_best_refine_map_coeffs.mtz
</PRE>

<LI>MTZ file with FP, phases and HL coeffs if present, and freeR_flags
used in refinement
<PRE style="face=courier">exptl_fobs_phases_freeR_flags.mtz
</PRE>
NOTE: The labels for this mtz file are typically:
<PRE style="face=courier"> FP SIGFP PHIM FOMM HLAM HLBM HLCM HLDM FreeR_flag
</PRE>
The file exptl_fobs_phases_freeR_flags.mtz has a copy of the (experimental) 
HL coefficients that were input to autobuild.  The labels HLAM HLBM etc 
have the ending "M" because they were copied by resolve and it outputs these
labels...but in fact they are not density modified phases from autobuild, 
just copied straight from the input data file.

<LI>Final log file for model-building
<PRE style="face=courier">overall_best.log
</PRE>

<LI>Final log file for refinement
<PRE style="face=courier">overall_best.log_refine
</PRE>

<LI>Evaluation of fit of model to map
<PRE style="face=courier">overall_best.log_eval
</PRE>

<LI>Summary of NCS information
<PRE style="face=courier">ncs_info.ncs
</PRE>
</LI>
</UL>

<P><H5><I>Standard building, rebuild_in_place, and multiple-models </I></H5><P>
The AutoBuild Wizard has two overall methods for building a model.  </p>
<p>The first method (standard build) is to 
build a model from scratch. This involves identification 
of where helices (and strands, for proteins) are located, extension using
fragment libraries, connection of segments, identification of side-chains,
and sequence alignment.  These methods are augmented in the standard building 
procedure by loop-fitting and building model outside of the region that has
already been built.</p></p></p></p>
<p>The second method (rebuild_in_place) takes an existing model and 
rebuilds it without adding or deleting any residues and without changing
the connectivity of the chain.  The way this works is a segment of the model 
is deleted and then is filled-in again by rebuilding from the remaining
ends. This is repeated for overlapping segments covering the entire model.
NOTE: If you are using rebuild_in_place then your model must be quite
similar to your sequence file, and in particular the model must not 
extend in the N-terminal direction beyond your sequence file. Minor edits
(amino acid replacements) will be done automatically.
</p>
<p>The multiple-models approach really has two levels of multiple models.
At the first level, several (multiple_models_group_number, default is
number_of_parallel_models) models are built (using rebuild_in_place) and
are then recombined into a single good model. At the next level, this whole
process may be done more than once (multiple_models_number times), yielding
several very good models.  By default, if you ask for rebuild_in_place, then
you will get a single very good model, created by running rebuild_in_place
several times and recombining the models.

<P><H5><I>Parallel jobs, nproc, nbatch, number_of_parallel_models and 
how AutoBuild works in parallel
</I></H5><P>
The AutoBuild Wizard is set up to take advantage of multi-processor
machines or batch queues by splitting the work into separate tasks. 
See 
  <A href="tutorial_build.htm">Tutorial 4: Iterative model-building,
      density modification and refinement
      starting from experimental phases </A>
   and 
  <A href="tutorial_rebuild.htm">Tutorial 6: Automatically
  rebuilding a structure solved by Molecular Replacement</A> for
a description of the method used by the AutoBuild Wizard to run
build jobs as sub-processes and to combine the results into single models.
</p>

 <p>Here
are the key factors that determine how splitting model-building into
batches and running them on one or more processors works:
</P>
<UL>
<LI><b>nbatch</b> is the number of batches of work. As long as nbatch is
fixed then the results of running the Wizard will be the same, no matter
how many processors are used.  It is most efficient however to have
nbatch be at least as large as nproc, the number of processors. Otherwise
some processors may end up doing nothing. The default is nbatch=3. The
value of nbatch is used to set other defaults 
(such as number_of_parallel_models).
 
<LI><b>nproc</b> is the number of processors to split the work among

<LI><b>number_of_parallel_models</b> is the number of models to build
at once.  The default is to set number_of_parallel_models=nbatch. This 
affects both standard building (number_of_parallel_models sets how many
initial models to build) and rebuild_in_place (number_of_parallel_models
determines whether a single model is built or a set of models are built
and recombined into a single model).

</UL>
<P>
Phenix.autobuild is set up so that you can specify the number of processors (nproc) and  the number of batches (nbatch) as you indicated in your command.  Additionally you will want to set two more parameters:

<PRE style="face=courier">run_command ="command you use to submit a job to your system"
background=False   # probably false if this is a cluster, true if this is a multiprocessor machine
</PRE>

If you have a queueing system with 20 nodes, then you probably submit jobs with something like 

"qsub -someflags myjob.csh"   # where someflags are whatever flags you use (or just "qsub myjob.csh" if no flags)

Then you might use 

<PRE style="face=courier"> run_command="qsub -someflags"  background=False nproc=20 nbatch=20
</PRE>
or
<PRE style="face=courier"> run_command="qsub"  background=False nproc=20 nbatch=20
</PRE>
or



If you have a 20-processor machine instead, then you might say

<PRE style="face=courier"> run_command=csh  background=True nproc=20 nbatch=20
</PRE>

so that it would run your jobs with csh on your machine, and run them all in the background (i.e., all at one time).


<P><H5><I>Model editing during rebuilding with the Coot-PHENIX interface 
</I></H5><P>
<P>The AutoBuild Wizard allows you to edit a model and give it back to the
Wizard during the iterative model-building, density modification and
refinement process. The Wizard will consider the model that you give it
along with the models that it generates automatically, and will choose the
parts of your model that fit the density better than other models.
<p>You can edit a model using the PHENIX-Coot interface. This 
interface is accessible through via the command-line.

<p>The PHENIX-Coot interface is accessible via the command-line.
When a model has been produced by the AutoSol Wizard,   
you can open a new window and
type:
<PRE style="face=courier">phenix.autobuild coot </PRE>
which will start Coot with your current map and model.
 
<p>When Coot has been loaded, your map and model will be displayed along with
a <b>PHENIX-Coot Interface</b> window. You can edit your model and then save 
it, giving it back to PHENIX with the button labelled something like
<b>Save model as COMM/overall_best_coot_7.pdb</b>. This button creates the
indicated file and also tells PHENIX to look for this file and to try and
include the contents of the model in the building process.
<p>The precise use of the model that you save depends on the type of
model-building that is being carried out by the AutoBuild Wizard. If you 
are using <b>rebuild_in_place</b> then the main-chain and side-chains of the
model are considered as replacements for the current working model. Any 
ligands or unrecognized residues are (by default) not rebuilt but are
included in refinement. By default, solvent in the model is ignored.
If you are not using <b>rebuild_in_place</b>,
only the main-chain conformation is considered, and the side-chains are
ignored.  Ligands (but not solvent) in the model are (by default) kept and 
included in refinement.
<p>As the AutoBuild Wizard continues to build new models and create new maps,
you can update in the PHENIX-Coot Interface to the current best model and
map with the button <b>Update with current files from PHENIX</b>.

<P><H5><I>Resolution limits in AutoBuild</I></H5><P>
<P>There are several resolution limits used in AutoBuild. You can leave them
all to default, or you can set any of them individually. Here is a list of
these limits and how their default values are set:
<TABLE width=670 border=1>
 <TBODY>
  <TR>
    <TD>Name</TD>
    <TD>Description</TD>
    <TD>How default value is set </TD>
  </TR>
  <TR>
    <TD>resolution</TD>
    <TD>Overall resolution. Used as high-resolution limit for
     density modification. Used as default for refinement resolution 
       and model-building resolution if they are not set.</TD>
    <TD>Resolution of input datafile. If a hires datafile is 
       provided, the resolution of that data is used.  </TD>
  </TR>
  <TR>
    <TD>refinement_resolution</TD>
    <TD>Resolution for refinement</TD>
    <TD>value of &quot;resolution&quot;</TD>
  </TR>
  <TR>
    <TD>resolution_build</TD>
    <TD>Resolution for model-building</TD>
    <TD>value of &quot;resolution&quot;</TD>
  </TR>
  <TR>
    <TD>overall_resolution</TD>
    <TD>Resolution to truncate all data. This should only be used
       if you need to truncate the data in order to get the Wizard to
       run. It causes the Wizard to ignore all data at higher resolution
       than overall_resolution.  It is normally better to use the
       resolution keyword to define the resolution limits, as that
       will keep all the data in the output and working files.</TD>
    <TD>None</TD>
  </TR>
  <TR>
    <TD>multiple_models_starting_resolution</TD>
    <TD>Resolution for the initial rebuilding of a model in the multiple-models
        procedure. Normally a low resolution to generate diversity.</TD>
    <TD>4 A by default</TD>
  </TR>
 </TBODY>
</TABLE>

      <P><H5><U>Sample AutoBuild Commands</U></H5><P>

<P>NOTE: Output files will be in subdirectories labelled 
&quot;AutoBuild_run_1_&quot; &quot;AutoBuild_run_2_&quot; etc.</P>


<H5>Run AutoBuild beginning with experimental data</H5><P>
<PRE style="face=courier">phenix.autobuild data=solve_1.mtz seq_file=seq.dat
input_ncs_file=ha.pdb
</PRE>
<P> Here the data in solve_1.mtz (FP SIGFP PHIB FOM HLA HLB HLC HLD) will be
used as the starting point for density modification. Then a model will be
built and refined. In subsequent cycles the models that have been built
will be used to improve the phases in density modification. If NCS can be
found from the sites in ha.pdb or from any models that are built, 
then NCS will be used in density modification.
<P>

<H5>Run AutoBuild beginning with a model and rebuild in place</H5><P>
<PRE style="face=courier">phenix.autobuild data=w1.sca seq.dat model=coords.pdb \
rebuild_in_place=True
</PRE>
<P>Here &quot;rebuild_in_place=True&quot; tells AutoBuild to keep the overall
model you have supplied, not to add or subtract residues from it, except that
AutoBuild will try to edit the model to match the sequence in 
your sequence file.  
The AutoBuild Wizard will use your model and the data in w1.sca to generate
starting phases, then it will carry out density modification to improve those 
phases, and adjust your model, rebuilding the model to match the resulting map
and refining the model.
This will be done iteratively, with the new model from each cycle being used
at the start of the next one. If NCS is found in your model then it will
be used in the density modification process.
<P>
<H5>Add more residues to a model or rebuild a model</H5>
<PRE style="face=courier">phenix.autobuild data=solve_1.mtz seq_file=seq.dat \
   model=coords.pdb rebuild_in_place=False
</PRE>
<P>Here &quot;rebuild_in_place=False&quot; tells AutoBuild to build a new
model, adding or subtracting residues as necessary.
The data in solve_1.mtz (FP SIGFP PHIB FOM HLA HLB HLC HLD) will be
used along with your model as the starting point for density 
modification. Then a new model will be
built and refined. In subsequent cycles the models that have been built
will be used to improve the phases in density modification. If NCS is 
found in your model or any model that is built, then it will be used
in density modification.
<P>

<H5>Run AutoBuild automatically after AutoSol</H5><P>
<PRE style="face=courier">phenix.autobuild after_autosol
</PRE>
<p>AutoBuild will identify the AutoSol run (in your working directory) with
the highest overall score, then it will take the experimental phases
(solve_xx.mtz or phaser_xx.mtz, where xx is the solution number) from
that run, along with the corresponding density-modified map (resolve_xx.mtz)
and the heavy_atom file (ha_xx.pdb_formatted.pdb) as inputs. Additionally,
if the input data have not been corrected for anisotropy, data for
refinement are read in from exptl_fobs_freeR_flags_xx.mtz. (If the
input data have been corrected for anisotropy you will have to supply a
refinement file with input_refinement_file=xxx.mtz)
<p>AutoBuild will then build a model, refine it, use the refined model
in density modification, then iterate the model-building, refinement, and 
density modification process until no further improvement in the model occurs.

<H5>Merge in hires data</H5><P>
<PRE style="face=courier">phenix.autobuild data=solve_2.mtz hires_file=w1.sca  seq_file=seq.dat
</PRE>
The high-resolution data in w1.sca will be used for FP and SIGFP. 
Other information from solve_2.mtz (PHIB FOM HLA HLB HLC HLD) will be kept.

<H5>Truncate density at heavy-atom sites</H5><P>
<PRE style="face=courier">phenix.autobuild data=solve_2.mtz seq_file=seq.dat input_ha_file=ha.pdb truncate_ha_sites_in_resolve=True
</PRE>
The heavy-atom sites in ha.pdb will be used to mark locations where
high density is to be ignored during initial cycles of density modification.
This can be useful if the heavy-atom peaks are very pronounced in the
experimental map.

<H5>Skip NCS in model_building and refinement</H5>
<PRE style="face=courier">phenix.autobuild data=solve_2.mtz seq_file=seq.dat find_ncs=False refine_with_ncs=False
</PRE>
The keyword &quot;find_ncs=False&quot; disables the finding of NCS from the
models that are built and its use in density modification and model-building.
The keyword &quot;refine_with_ncs=False&quot; disables finding NCS and its
use in the refinement process. Together they prevent all use of NCS.
<H5>Make a SA-omit map around atoms in target.pdb</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb omit_box_pdb=target.pdb   composite_omit_type=sa_omit
</PRE>
Coefficients for the output omit map will be in the  file
resolve_composite_map.mtz in the subdirectory OMIT/ .
An additional map coefficients file omit_region.mtz will show you the
region that has been omitted. 
(Note: be sure to use the weights in both
resolve_composite_map.mtz and omit_region.mtz).

<H5>Make a simple composite omit map</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb composite_omit_type=simple_omit
</PRE>
Coefficients for the output omit map will be in the  file
resolve_composite_map.mtz in the subdirectory OMIT/ .

<H5>Make a SA composite omit map</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb composite_omit_type=sa_omit
</PRE>
Coefficients for the output simulated-annealing composite
omit map will be in the  file
resolve_composite_map.mtz in the subdirectory OMIT/ .

<H5>Make an iterative-build omit map around atoms in target.pdb</H5><P>
<PRE style="face=courier">phenix.autobuild data=w1.sca model=coords.pdb omit_box_pdb=target.pdb \
   composite_omit_type=iterative_build_omit
</PRE>
Coefficients for the output omit map will be in the  file
resolve_composite_map.mtz in the subdirectory OMIT/ .
An additional map coefficients file omit_region.mtz will show you the
region that has been omitted.
(Note: be sure to use the weights in both
resolve_composite_map.mtz and omit_region.mtz).

<H5>Make a sa-omit map around residues 3 and 4 in chain A of coords.pdb</H5><P>
<PRE style="face=courier">phenix.autobuild data=w1.sca model=coords.pdb omit_box_pdb=coords.pdb \
   omit_res_start_list=3 omit_res_end_list=4 omit_chain_list=A   \
   composite_omit_type=sa_omit
</PRE>
Coefficients for the output omit map will be in the  file
resolve_composite_map.mtz in the subdirectory OMIT/ .
An additional map coefficients file omit_region.mtz will show you the
region that has been omitted.
(Note 1: be sure to use the weights in both 
resolve_composite_map.mtz and omit_region.mtz).

<H5>Create one very good rebuilt model</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb multiple_models=True \
  include_input_model=True  \
  multiple_models_number=1 n_cycle_rebuild_max=5
</PRE>
The final model will be in the subdirectory MULTIPLE_MODELS in
the file all_models.pdb (this file will contain just one model).
<p>
Note that this procedure will keep the sequence that is present in coords.pdb.
If you supply a sequence file it will edit the sequence of coords.pdb 
to match your sequence file and discard any residues that do not match.
(If you want to input a sequence file but not edit the sequence in coords.pdb
and not discard any non-matching residues, then specify also edit_pdb=False.)
<p>Note also that if include_input_model=True then no randomization cycle
will be carried out and multiple_models_starting_resolution is ignored.

<H5>Touch up a model </H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb \
touch_up=True worst_percent_res_rebuild=2 min_cc_res_rebuild=0.8
</PRE>
 You can rebuild just the worst parts of your model by settting
        touch_up=True.  You can decide what parts to rebuild based on
        a minimum model-map correlation (by residue).
        You can decide how much to rebuild
        using worst_percent_res_rebuild or with min_cc_res_rebuild, or both.

<H5>Create 20 very good rebuilt models that are as different as possible</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb multiple_models=True \
   multiple_models_number=20 n_cycle_rebuild_max=5
</PRE>
The 20 final models will be in the subdirectory MULTIPLE_MODELS in
the file all_models.pdb. 
This procedure is useful for generating an ensemble of models that are 
each individually consistent with the data, and yet are diverse. The variation
among these models is an indication of the uncertainty in each of the models.
Note that the ensemble of models is not a representation of the ensemble of
structures that is truly present in the crystal.

<H5>Morph an MR model and rebuild it</H5><P>
<PRE style="face=courier">phenix.autobuild data=data.mtz model=MR.pdb \
morph=True rebuild_in_place=False seq_file=seq.dat
</PRE>
<p>You can have autobuild morph your input model, distorting it to match
the density-modified map that is produced from your model and data. This
can be used to make an improved starting model in cases where the MR model
is very different than the structure that is to be solved.  For the morphing
to work, the two structures must be topologically similar and differ
mostly by movements of domains or motifs such as a group of helices or
a sheet.
<p>The morphing process consists of identifying a coordinate shift to apply
to each N (or P for nucleic acids) atom that maximizes the local density
correlation between the model and the map. This is smoothed and applied to
the structure to generate a morphed structure.


<H5>Build an RNA chain</H5><P>
<PRE style="face=courier">phenix.autobuild data=solve_1.mtz seq_file=seq.dat chain_type=RNA
</PRE>

<H5>Build a DNA chain</H5><P>
<PRE style="face=courier">phenix.autobuild data=solve_1.mtz seq_file=seq.dat chain_type=DNA
</PRE>

<H5>Density-modify with or without a model and make maps </H5><P>
You can use the AutoBuild Wizard as a convenient way to run resolve
density modification with or without including model-based information.  Just
use a command like this:
<PRE style="face=courier">phenix.autobuild data=data.mtz model=coords.pdb \
   maps_only=True seq_file=seq.dat 
</PRE>
The Wizard will calculate the same map that it would normally calculate given
these data, and then it will write the map out and stop.

<H5>Density-modify starting with your map coefficients and make maps </H5><P>
You can use the AutoBuild Wizard as a convenient way to run resolve
density modification starting with map coefficients you define.  Just
use a command like this:
<PRE style="face=courier">phenix.autobuild data=data.mtz \
     maps_only=True  seq_file=seq.dat \
     map_file=starting_map.mtz map_labels="2FOFCWT PH2FOFCWT"

</PRE>
The Wizard will start with the phases in starting_map.mtz calculate the same map that it would normally calculate given
these data, and then it will write the map out and stop.

<H5>Calculate a prime-and-switch map </H5><P>
<PRE style="face=courier">
phenix.autobuild data=data.mtz solvent_fraction=.6 \
   ps_in_rebuild=True model=coords.pdb maps_only=True 
</PRE>
The output prime-and-switch map will be in the file prime_and_switch.mtz.


      <P><H5><U>Possible Problems</U></H5><P>

<P><H5>General Limitations</H5><P>


<UL>

<LI> 
The AutoBuild wizard edits input PDB files to remove multiple
conformations. It will also renumber residues if the file contains residues with
insertion codes.  All references to residue numbers (e.g. 
rebuild_res_start_list) refer to the edited, renumbered model. 
This model can be found in the AutoBuild_run_1_ (or appropriate) 
directory as &quot;edited_pdb.pdb&quot;.

<LI> 
If you are using rebuild_in_place then your model must be quite
similar to your sequence file, and in particular the model must not 
extend in the N-terminal direction beyond your sequence file. Minor edits
(amino acid replacements) will be done automatically.

<LI> The AutoBuild wizard expects residue numbers to not decrease along a
chain.  It will stop if residue 250 in chain B is found 
between residues 116 and 117 in the same chain,
for example. To get around this, use insertion codes (make residue 250
residue 116A instead).

<P><LI>The keywords &quot;cell&quot; and &quot;sg&quot; have 
been replaced with &quot;unit_cell&quot; and &quot;space_group&quot; to
make the keywords the same as in other phenix applications.

<LI>The AutoBuild model-building can only build one type of chain at a 
time (default chain_type='PROTEIN'; other choices are RNA and DNA).  If you
supply a PDB file containing more than one type of chain for rebuilding, 
then all the residues that are not that type of chain are treated as
ligands and are (by default, keep_input_ligands=True) 
included in refinement but not in rebuilding. Any
input solvent molecules are (by default, keep_input_waters=False) ignored.  

<P>You can include more than one type of chain in rebuilding by supplying 
one type of chains as ligands with input_lig_file_list and rebuilding another
type:
<PRE style="face=courier">chain_type=PROTEIN  # build only protein
input_lig_file_list=MyDNA.pdb  # just read in DNA coordinates and include in refinement
</PRE>
In this case only protein chains will be built, but the DNA coordinates in
MyDNA.pdb will be included in all refinements and will be written out
to the final coordinate file.  You may wish to add the keyword:
<PRE style="face=courier">keep_pdb_atoms=False  #keep the ligand atoms if model (pdb) and ligand overlap</PRE>
which will tell AutoBuild that the ligand (DNA) atoms are to be kept if the
model that is being built (protein) overlaps with it. (The default is to keep 
the model that is being built and to discard any ligand atoms that overlap).

<p> This whole process is likely to require substantial editing of the 
PDB files by hand because when you build DNA, a lot of chains are going to
be built into the protein region, and when you build protein, it is going to
be accidentally built into the DNA.


<LI>Any file in input_lig_file_list containing ATOM records will have them 
replaced with HETATM records. This is so that the rebuild_in_place algorithm
does not try to use them in rebuilding.  

<LI>The ligand generation routine in phenix.elbow will not generate
heme groups at this point. Most other ligands can be automatically
generated.

<LI>If your input data file contains both intensity data and
amplitude data, only the amplitude data is exposed in the AutoBuild
Wizard.  If you want to use the intensity data then you have to create a
file that does not have amplitude data in it.

<LI>If your input data file has only intensity data and you wish to
specify which columns of data the AutoBuild Wizard is to use,
then you have to specify the names that the columns will have
AFTER importing the data and conversion to amplitudes, 
not the original column names.
<p>These column names may not be obvious. Here is how to find out what they
will be.  Do a quick dummy run like this with XXX as labels:
<PRE style="face=courier">
phenix.autobuild w2.sca coords.pdb input_labels="XXX XXX"
</PRE>
The Wizard will print out a list of available labels like this:
<PRE style="face=courier">
Sorry, the label XXX does not exist as an amplitude array in
the input_data_file ImportRawData_run_8_/w2_PHX.mtz
...available labels are: ['w2', 'SIGw2', 'None']
</PRE>
Then you know that the correct command is:
<PRE style="face=courier">
phenix.autobuild w2.sca coords.pdb input_labels="w2 SIGw2"
</PRE>

<LI>The AutoBuild Wizard cannot build modified residues.  If you supply
a model with modified residues, these will be taken out of the
chain and treated as ligands, and the chain will
be broken at that point. By default the modified residues will be added to
your model just before refinement and a cif definitions file will be
automatically generated for these residues.
You can also add these residues with
the input_lig_file_list procedure if you want.
</LI>
<LI>The AutoBuild Wizard will not build very short chains unless you
set the variable group_ca_length (default=4 for building a model
from scratch) to a smaller number. The
shortest chain that will be built is group_ca_length.  If you use
rebuild_in_place, then the default shortest chain allowed is 1 residue, 
so any part of a model you supply is rebuilt.
</LI>
</UL>

<P><H5>Specific limitations and problems</H5><P>


<UL>
<LI>By default the AutoBuild Wizard splits jobs into one or more parts 
(determined by the parameter &quot;nbatch&quot;) and runs
them as sub-processes.  These may run sequentially or in parallel, 
depending on the value of the parameter &quot;nproc&quot; . In some cases the
running of sub-processes can lead to timing errors in which a file is
not written fully before it is to be read by the next process. This appears
more often when jobs are run on nfs-mounted disks than on a local disk.
If this occurs, a solution is to set the parameter &quot;nbatch=1&quot;
so that the jobs not be run as sub-processes.  You can also specify
&quot;number_of_parallel_models=1&quot; which will do much the same
thing. Note that changing the
value of &quot;nbatch&quot; will normally change the results of running the
Wizard. (Changing the value of &quot;nproc&quot; does not change the results,
it changes only how many jobs are run at once.)

<LI>In many versions of the shell tcsh (and csh), the length of the
shell variable PATH is limited (for example to 4096 characters).  If your
PATH is quite long then when AutoBuild runs a sub-process, it may
accidentally increase the PATH to a value that is over the limit.  The
symptom is that you get a message like &quot;Word too long&quot;.  If this
happens, try 'echo $PATH' to see if it is very long...and if so see if 
you can remove some entries in it.
Or...you may want to shorten your path in PHENIX by specifying: 
 remove_path_word_list='coot cns ccp4' (add as many paths that 
you have but do not need within PHENIX).
Or...you may want to install a new version of tcsh which will  allow a much 
longer path. You can get a new version from ftp://ftp.astron.com/pub/tcsh/

<LI>The size of the asymmetric unit in the SOLVE/RESOLVE portion of 
the AutoBuild wizard is limited by the memory in your computer and the
binaries used. The Wizard is supplied with regular-size ("", size=6), 
giant ("_giant", size=12), huge ("_huge", size=18) and extra_huge
("_extra_huge", size=36).  Larger-size versions can be obtained on
request.

<LI>The AutoBuild Wizard can take most settings of most space groups,
however it can only use the hexagonal setting of rhombohedral space groups 
(eg., #146 R3:H or #155 R32:H), and it cannot use space groups 114-119 (not
found in macromolecular crystallography) even in the standard setting 
due to difficulties with the use of asuset in the version of ccp4 libraries 
used in PHENIX for these settings and space groups.

</UL>

      <P><H5><U>Literature</U></H5><P>

<TABLE width=670 border=0>
  <TBODY>
  <TR>
    <TD>
      <TABLE cellSpacing=3 cellPadding=1 width="100%" align=center border=0>
        <TBODY>

      <TR id="terwilliger2008">
        <TD ALIGN=LEFT BGCOLOR="#eeeee8">
          <FONT FACE="Verdana,Helvetica,Arial" COLOR="#000000">
          <b>Iterative model building, structure refinement and density 
           modification with the PHENIX AutoBuild wizard.</b>
          T. C. Terwilliger, R. W. Grosse-Kunstleve, P. V. Afonine, 
           N. W. Moriarty, P. H. Zwart, L.-W. Hung, R. J. Read, and P. D. Adams
          <a href="http://www.iucr.org/cgi-bin/paper?ba5109">
          <i>Acta Cryst.</i> <b>D64</b>, 61-69 (2008)</a><br>
          </FONT>
        </TD>
        <TD ALIGN=CENTER BGCOLOR="#ffffff">
          <A HREF="http://www.phenix-online.org/papers/ba5109_reprint.pdf" 
          TARGET="_main"><FONT FACE="Verdana,Helvetica,Arial" COLOR="#000000">[pdf]
           </FONT></A>           
        </TD>
      </TR>



       <TR id=terwilliger2007b>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Interpretation of ensembles created by
            multiple iterative rebuilding of macromolecular models.</B> T. C.
            Terwilliger, R. W. Grosse-Kunstleve, P. V. Afonine, P. D. Adams, N.
            W. Moriarty P. H. Zwart, R. J. Read, D. Turk and L.-W. Hung <A
            href="http://www.iucr.org/cgi-bin/paper?wd5073"><I>Acta Cryst.</I>
            <B>D63</B>, 597-610 (2007)</A><BR></FONT></TD>
          <TD align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/wd5073_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>



        <TR id=terwilliger2004a>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Using prime-and-switch phasing to reduce
            model bias in molecular replacement.</B> T. C. Terwilliger <A
            href="http://www.iucr.org/cgi-bin/paper?ba5057"><I>Acta Cryst.</I>
            <B>D60</B>, 2144-2149 (2004)</A><BR></FONT></TD>
          <TD align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/ba5057_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>

        <TR id=terwilliger2003c>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Improving macromolecular atomic models at
            moderate resolution by automated iterative model building,
            statistical density modification and refinement.</B> T.C.
            Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?dz0002"><I>Acta Cryst.</I>
            <B>D59</B>, 1174-1182 (2003)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/dz0002_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>

        <TR id=terwilliger2003d>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Statistical density modification using local
            pattern matching.</B> T.C. Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?zd5004"><I>Acta Cryst.</I>
            <B>D59</B>, 1688-1701 (2003)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/dz5004_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>
        <TR id=terwilliger2003b>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Automated side-chain model building and
            sequence assignment by template matching.</B> T.C. Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?gr2292"><I>Acta Cryst.</I>
            <B>D59</B>, 45-49 (2003)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/gr2292_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>


        <TR id=terwilliger2003a>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Automated main-chain model building by
            template matching and iterative fragment extension.</B> T.C.
            Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?gr2291"><I>Acta Cryst.</I>
            <B>D59</B>, 38-44 (2003)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/gr2291_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>
        <TR id=terwilliger2002b>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Rapid automatic NCS identification using
            heavy-atom substructures</B> T.C. Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?gr2270"><I>Acta Cryst.</I>
            <B>D58</B>, 2213-2215 (2002)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/gr2270_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>
        <TR id=terwilliger2002a>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>Statistical density modification with
            non-crystallographic symmetry</B> T.C. Terwilliger. <A
            href="http://www.iucr.org/cgi-bin/paper?gr2269"><I>Acta Cryst.</I>
            <B>D58</B>, 2082-2086 (2002)</A><BR></FONT></TD>
          <TD vAlign=top align=center bgColor=ffffff><A
            href="http://www.phenix-online.org/papers/gr2269_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>

        <TR id=terwilliger2000>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B> Maximum likelihood density modification </B>
            T. C. Terwilliger
            <A href= "http://www.iucr.org/cgi-bin/paper?gr2006" ><I>
             Acta Cryst.  </I> <B> D56 </B>, 965-972 (2000) </A><BR></FONT></TD>

          <TD align=center bgColor=ffffff><A
            href= "http://www.phenix-online.org/papers/related/resolve_reprint.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>

        <TR id=terwilliger2001a>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B>
            Maximum-likelihood density modification with pattern recognition
            of structural motifs.  </B>
             T. C. Terwilliger
            <A href= "http://www.iucr.org/cgi-bin/paper?gr2164" ><I>
            Acta Cryst.  </I> <B> D57 </B>, 1755-1762 (2001) </A><BR></FONT></TD>

          <TD align=center bgColor=ffffff><A
            href= "http://www.phenix-online.org/papers/related/gr2164_pattern_recog_01.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>


        <TR id=terwilliger2001b>
          <TD align=left bgColor=eeeee8><FONT 
            color=000000 size=2><B> Map-likelihood phasing </B>
            T. C. Terwilliger
            <A href= "http://www.iucr.org/cgi-bin/paper?gr2165" ><I>
             Acta Cryst.  </I> <B> D57 </B>, 1763-1775 (2001) </A><BR></FONT></TD>
          <TD align=center bgColor=ffffff><A
            href= "http://www.phenix-online.org/papers/related/gr2165_map_likelihood01.pdf"
            target=_main><FONT  color=000000
            size=2>[pdf]</FONT></A> </TD></TR>



        </TBODY>
     </TABLE>
    </TD>
  </TR>
  </TBODY>
</TABLE>

      <P><H5><U>Additional information</U></H5><P>


<!-- REMARK PHENIX BODY END-->
